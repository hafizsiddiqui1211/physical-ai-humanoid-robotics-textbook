"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook=globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[63],{2926:(n,i,e)=>{e.r(i),e.d(i,{assets:()=>a,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"ai/perception-manipulation","title":"Perception and Manipulation","description":"Introduction to Robotic Perception","source":"@site/docs/ai/perception-manipulation.md","sourceDirName":"ai","slug":"/ai/perception-manipulation","permalink":"/physical-ai-humanoid-robotics-textbook/docs/ai/perception-manipulation","draft":false,"unlisted":false,"editUrl":"https://github.com/hafizsiddiqui1211/physical-ai-humanoid-robotics-textbook/tree/main/docusaurus/docs/ai/perception-manipulation.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"SLAM and Navigation","permalink":"/physical-ai-humanoid-robotics-textbook/docs/ai/slam-navigation"},"next":{"title":"Humanoid Robot Kinematics and Dynamics","permalink":"/physical-ai-humanoid-robotics-textbook/docs/humanoid/kinematics-dynamics"}}');var r=e(4848),l=e(8453);const t={sidebar_position:3},o="Perception and Manipulation",a={},c=[{value:"Introduction to Robotic Perception",id:"introduction-to-robotic-perception",level:2},{value:"Perception Pipeline",id:"perception-pipeline",level:2},{value:"Data Acquisition",id:"data-acquisition",level:3},{value:"Preprocessing",id:"preprocessing",level:3},{value:"Feature Extraction",id:"feature-extraction",level:3},{value:"Object Recognition",id:"object-recognition",level:3},{value:"Manipulation Fundamentals",id:"manipulation-fundamentals",level:2},{value:"Grasping",id:"grasping",level:3},{value:"Manipulation Planning",id:"manipulation-planning",level:3},{value:"Control Strategies",id:"control-strategies",level:3},{value:"Computer Vision for Robotics",id:"computer-vision-for-robotics",level:2},{value:"3D Vision",id:"3d-vision",level:3},{value:"Object Detection and Tracking",id:"object-detection-and-tracking",level:3},{value:"Pose Estimation",id:"pose-estimation",level:3},{value:"Deep Learning in Perception",id:"deep-learning-in-perception",level:2},{value:"Convolutional Neural Networks",id:"convolutional-neural-networks",level:3},{value:"3D Deep Learning",id:"3d-deep-learning",level:3},{value:"Domain Adaptation",id:"domain-adaptation",level:3},{value:"Manipulation Techniques",id:"manipulation-techniques",level:2},{value:"Grasp Synthesis",id:"grasp-synthesis",level:3},{value:"Dexterous Manipulation",id:"dexterous-manipulation",level:3},{value:"Contact-Rich Manipulation",id:"contact-rich-manipulation",level:3},{value:"ROS 2 Perception Stack",id:"ros-2-perception-stack",level:2},{value:"Image Pipeline",id:"image-pipeline",level:3},{value:"Point Cloud Processing",id:"point-cloud-processing",level:3},{value:"Perception Nodes",id:"perception-nodes",level:3},{value:"Manipulation Frameworks",id:"manipulation-frameworks",level:2},{value:"MoveIt! Integration",id:"moveit-integration",level:3},{value:"Task and Motion Planning",id:"task-and-motion-planning",level:3},{value:"Sensor Fusion",id:"sensor-fusion",level:2},{value:"Multi-Modal Integration",id:"multi-modal-integration",level:3},{value:"Kalman Filtering",id:"kalman-filtering",level:3},{value:"Safety and Reliability",id:"safety-and-reliability",level:2},{value:"Perception Safety",id:"perception-safety",level:3},{value:"Manipulation Safety",id:"manipulation-safety",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Real-Time Processing",id:"real-time-processing",level:3},{value:"Quality Metrics",id:"quality-metrics",level:3},{value:"Applications",id:"applications",level:2},{value:"Industrial Manipulation",id:"industrial-manipulation",level:3},{value:"Service Robotics",id:"service-robotics",level:3},{value:"Research Applications",id:"research-applications",level:3},{value:"Challenges and Future Directions",id:"challenges-and-future-directions",level:2},{value:"Current Challenges",id:"current-challenges",level:3},{value:"Emerging Trends",id:"emerging-trends",level:3},{value:"Testing and Validation",id:"testing-and-validation",level:2},{value:"Simulation Testing",id:"simulation-testing",level:3},{value:"Real-World Validation",id:"real-world-validation",level:3}];function d(n){const i={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(i.header,{children:(0,r.jsx)(i.h1,{id:"perception-and-manipulation",children:"Perception and Manipulation"})}),"\n",(0,r.jsx)(i.h2,{id:"introduction-to-robotic-perception",children:"Introduction to Robotic Perception"}),"\n",(0,r.jsx)(i.p,{children:"Robotic perception is the process by which robots interpret sensory information to understand their environment and their own state. This capability is fundamental to robot autonomy, enabling tasks such as navigation, manipulation, and human-robot interaction. Perception systems transform raw sensor data into meaningful information that guides robot behavior."}),"\n",(0,r.jsx)(i.h2,{id:"perception-pipeline",children:"Perception Pipeline"}),"\n",(0,r.jsx)(i.h3,{id:"data-acquisition",children:"Data Acquisition"}),"\n",(0,r.jsx)(i.p,{children:"The perception pipeline begins with sensor data:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Cameras"}),": RGB, depth, stereo, thermal"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Range sensors"}),": LIDAR, sonar, ToF"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Inertial sensors"}),": IMUs, gyroscopes"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Tactile sensors"}),": Force, pressure, slip detection"]}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"preprocessing",children:"Preprocessing"}),"\n",(0,r.jsx)(i.p,{children:"Raw sensor data requires preprocessing:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Calibration"}),": Intrinsic and extrinsic parameters"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Filtering"}),": Noise reduction and outlier removal"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Registration"}),": Multi-sensor data alignment"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Normalization"}),": Data standardization"]}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"feature-extraction",children:"Feature Extraction"}),"\n",(0,r.jsx)(i.p,{children:"Extract meaningful features from sensor data:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Visual features"}),": Edges, corners, textures"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Geometric features"}),": Planes, lines, shapes"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Statistical features"}),": Moments, histograms"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Learned features"}),": Deep learning representations"]}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"object-recognition",children:"Object Recognition"}),"\n",(0,r.jsx)(i.p,{children:"Identify and classify objects:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Template matching"}),": Pattern recognition"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Feature-based"}),": Keypoint matching"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Deep learning"}),": CNN-based classification"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Semantic segmentation"}),": Pixel-level classification"]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"manipulation-fundamentals",children:"Manipulation Fundamentals"}),"\n",(0,r.jsx)(i.h3,{id:"grasping",children:"Grasping"}),"\n",(0,r.jsx)(i.p,{children:"The ability to securely grasp objects:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Pre-shape grasping"}),": Fixed hand configurations"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Power grasps"}),": Stable, force-closure grasps"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Precision grasps"}),": Fine manipulation"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Adaptive grasps"}),": Shape-adaptive approaches"]}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"manipulation-planning",children:"Manipulation Planning"}),"\n",(0,r.jsx)(i.p,{children:"Plan manipulation sequences:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Grasp planning"}),": Object-specific grasp selection"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Trajectory planning"}),": Collision-free motion"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Force control"}),": Contact force management"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Task planning"}),": High-level action sequences"]}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"control-strategies",children:"Control Strategies"}),"\n",(0,r.jsx)(i.p,{children:"Execute manipulation tasks:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Position control"}),": Cartesian or joint space"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Force control"}),": Impedance and admittance"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Hybrid control"}),": Position and force"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Learning-based"}),": Imitation and reinforcement"]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"computer-vision-for-robotics",children:"Computer Vision for Robotics"}),"\n",(0,r.jsx)(i.h3,{id:"3d-vision",children:"3D Vision"}),"\n",(0,r.jsx)(i.p,{children:"Extract 3D information from images:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Stereo vision"}),": Triangulation from multiple views"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Structure from motion"}),": 3D reconstruction"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Multi-view stereo"}),": Dense 3D reconstruction"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"RGB-D processing"}),": Depth and color integration"]}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"object-detection-and-tracking",children:"Object Detection and Tracking"}),"\n",(0,r.jsx)(i.p,{children:"Locate and follow objects:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"2D detection"}),": Bounding box localization"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"3D detection"}),": 3D bounding boxes"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Instance segmentation"}),": Object instance labeling"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Multi-object tracking"}),": Temporal association"]}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"pose-estimation",children:"Pose Estimation"}),"\n",(0,r.jsx)(i.p,{children:"Determine object position and orientation:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Template-based"}),": Model matching"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Feature-based"}),": Keypoint alignment"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Deep learning"}),": Direct pose regression"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"PnP algorithms"}),": Perspective-n-Point"]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"deep-learning-in-perception",children:"Deep Learning in Perception"}),"\n",(0,r.jsx)(i.h3,{id:"convolutional-neural-networks",children:"Convolutional Neural Networks"}),"\n",(0,r.jsx)(i.p,{children:"CNNs for visual perception:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Image classification"}),": Object recognition"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Object detection"}),": Localization and classification"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Semantic segmentation"}),": Pixel-wise classification"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Instance segmentation"}),": Object instance separation"]}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"3d-deep-learning",children:"3D Deep Learning"}),"\n",(0,r.jsx)(i.p,{children:"Process 3D data with neural networks:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"PointNet"}),": Point cloud processing"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"VoxNet"}),": Volumetric convolution"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Graph neural networks"}),": Relational reasoning"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Transformer architectures"}),": Attention mechanisms"]}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"domain-adaptation",children:"Domain Adaptation"}),"\n",(0,r.jsx)(i.p,{children:"Transfer models across domains:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Synthetic-to-real"}),": Simulation to reality"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Style transfer"}),": Domain randomization"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Unsupervised adaptation"}),": No target labels"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Test-time adaptation"}),": Online learning"]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"manipulation-techniques",children:"Manipulation Techniques"}),"\n",(0,r.jsx)(i.h3,{id:"grasp-synthesis",children:"Grasp Synthesis"}),"\n",(0,r.jsx)(i.p,{children:"Generate effective grasps:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Analytical methods"}),": Force-closure analysis"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Sampling-based"}),": Random grasp generation"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Learning-based"}),": Grasp quality prediction"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Geometric approaches"}),": Shape analysis"]}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"dexterous-manipulation",children:"Dexterous Manipulation"}),"\n",(0,r.jsx)(i.p,{children:"Fine motor control:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"In-hand manipulation"}),": Object repositioning"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Bimanual coordination"}),": Two-handed tasks"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Tool use"}),": Functional manipulation"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Assembly tasks"}),": Precision operations"]}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"contact-rich-manipulation",children:"Contact-Rich Manipulation"}),"\n",(0,r.jsx)(i.p,{children:"Handle complex contacts:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Force control"}),": Compliance and impedance"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Tactile sensing"}),": Contact feedback"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Slip detection"}),": Prevent grasp failures"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Haptic feedback"}),": Human-robot collaboration"]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"ros-2-perception-stack",children:"ROS 2 Perception Stack"}),"\n",(0,r.jsx)(i.h3,{id:"image-pipeline",children:"Image Pipeline"}),"\n",(0,r.jsx)(i.p,{children:"Process camera data in ROS 2:"}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-yaml",children:"image_proc:\n  ros__parameters:\n    # Rectification parameters\n    use_sensor_time: false\n    queue_size: 5\n    # Processing options\n    debayering: true\n    rectification: true\n"})}),"\n",(0,r.jsx)(i.h3,{id:"point-cloud-processing",children:"Point Cloud Processing"}),"\n",(0,r.jsx)(i.p,{children:"Handle 3D data:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"PCL integration"}),": Point Cloud Library"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Filtering"}),": Outlier removal, downsampling"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Segmentation"}),": Ground plane, object separation"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Registration"}),": Multi-frame alignment"]}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"perception-nodes",children:"Perception Nodes"}),"\n",(0,r.jsx)(i.p,{children:"Standard ROS 2 perception nodes:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"image_transport"}),": Compressed image handling"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"cv_bridge"}),": OpenCV integration"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"tf2"}),": Coordinate frame transformations"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"message_filters"}),": Synchronized processing"]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"manipulation-frameworks",children:"Manipulation Frameworks"}),"\n",(0,r.jsx)(i.h3,{id:"moveit-integration",children:"MoveIt! Integration"}),"\n",(0,r.jsx)(i.p,{children:"Motion planning and manipulation:"}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-python",children:'import moveit_commander\nimport rospy\n\nclass ManipulationController:\n    def __init__(self):\n        self.robot = moveit_commander.RobotCommander()\n        self.scene = moveit_commander.PlanningSceneInterface()\n        self.move_group = moveit_commander.MoveGroupCommander("arm")\n\n    def pick_object(self, object_name):\n        # Plan and execute pick motion\n        grasp_poses = self.generate_grasps(object_name)\n        for grasp in grasp_poses:\n            if self.execute_grasp(grasp):\n                return True\n        return False\n'})}),"\n",(0,r.jsx)(i.h3,{id:"task-and-motion-planning",children:"Task and Motion Planning"}),"\n",(0,r.jsx)(i.p,{children:"Integrate high-level tasks:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"PDDL integration"}),": Planning domain definition"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Temporal planning"}),": Time-dependent tasks"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Contingency planning"}),": Failure recovery"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Human-aware planning"}),": Social navigation"]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"sensor-fusion",children:"Sensor Fusion"}),"\n",(0,r.jsx)(i.h3,{id:"multi-modal-integration",children:"Multi-Modal Integration"}),"\n",(0,r.jsx)(i.p,{children:"Combine different sensor modalities:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Visual-inertial"}),": Camera and IMU fusion"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"LiDAR-camera"}),": Range and color integration"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Tactile-visual"}),": Haptic and visual feedback"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Multi-modal learning"}),": Joint representation"]}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"kalman-filtering",children:"Kalman Filtering"}),"\n",(0,r.jsx)(i.p,{children:"Recursive state estimation:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Extended Kalman Filter"}),": Nonlinear systems"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Unscented Kalman Filter"}),": Better approximation"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Particle Filter"}),": Non-Gaussian distributions"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Information Filter"}),": Inverse covariance"]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"safety-and-reliability",children:"Safety and Reliability"}),"\n",(0,r.jsx)(i.h3,{id:"perception-safety",children:"Perception Safety"}),"\n",(0,r.jsx)(i.p,{children:"Ensure safe perception operation:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Validation"}),": Output verification"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Uncertainty quantification"}),": Confidence measures"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Anomaly detection"}),": Outlier identification"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Redundancy"}),": Multiple perception methods"]}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"manipulation-safety",children:"Manipulation Safety"}),"\n",(0,r.jsx)(i.p,{children:"Safe manipulation execution:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Collision checking"}),": Path validation"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Force limits"}),": Safe interaction forces"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Emergency stopping"}),": Immediate halt"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Human safety"}),": Collision avoidance"]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,r.jsx)(i.h3,{id:"real-time-processing",children:"Real-Time Processing"}),"\n",(0,r.jsx)(i.p,{children:"Meet timing constraints:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Parallel processing"}),": Multi-threading"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"GPU acceleration"}),": CUDA/TensorRT"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Optimized algorithms"}),": Efficient implementations"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Resource management"}),": Memory and computation"]}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"quality-metrics",children:"Quality Metrics"}),"\n",(0,r.jsx)(i.p,{children:"Evaluate perception performance:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Accuracy"}),": Correctness measures"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Precision/Recall"}),": Detection quality"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Latency"}),": Processing time"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Throughput"}),": Frames per second"]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"applications",children:"Applications"}),"\n",(0,r.jsx)(i.h3,{id:"industrial-manipulation",children:"Industrial Manipulation"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Assembly"}),": Precise component placement"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Picking"}),": Bin picking and sorting"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Quality inspection"}),": Visual quality control"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Packaging"}),": Automated packaging systems"]}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"service-robotics",children:"Service Robotics"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Household tasks"}),": Cleaning and organization"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Assistive robotics"}),": Elderly care support"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Restaurant service"}),": Food delivery"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Healthcare"}),": Surgical assistance"]}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"research-applications",children:"Research Applications"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Open-world manipulation"}),": Novel objects"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Human-robot collaboration"}),": Shared tasks"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Learning from demonstration"}),": Skill transfer"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Long-term autonomy"}),": Persistent operation"]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"challenges-and-future-directions",children:"Challenges and Future Directions"}),"\n",(0,r.jsx)(i.h3,{id:"current-challenges",children:"Current Challenges"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Real-world complexity"}),": Unstructured environments"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Robustness"}),": Failure handling"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Generalization"}),": Novel scenarios"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Learning efficiency"}),": Sample-efficient learning"]}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"emerging-trends",children:"Emerging Trends"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Foundation models"}),": Large-scale pre-trained models"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Embodied learning"}),": Learning through interaction"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Neuromorphic vision"}),": Event-based sensing"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Quantum computing"}),": Optimization algorithms"]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"testing-and-validation",children:"Testing and Validation"}),"\n",(0,r.jsx)(i.h3,{id:"simulation-testing",children:"Simulation Testing"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Gazebo integration"}),": Physics simulation"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Isaac Sim"}),": Photorealistic simulation"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Unity robotics"}),": Interactive environments"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Synthetic data"}),": Training data generation"]}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"real-world-validation",children:"Real-World Validation"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Benchmark datasets"}),": Standard evaluation"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Physical testing"}),": Real hardware validation"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Long-term studies"}),": Extended operation"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"User studies"}),": Human-robot interaction"]}),"\n"]}),"\n",(0,r.jsx)(i.p,{children:"Robotic perception and manipulation form the core capabilities that enable robots to interact with and understand their environment. Understanding these concepts and their implementation in modern robotic frameworks is essential for developing capable and safe robotic systems."})]})}function h(n={}){const{wrapper:i}={...(0,l.R)(),...n.components};return i?(0,r.jsx)(i,{...n,children:(0,r.jsx)(d,{...n})}):d(n)}},8453:(n,i,e)=>{e.d(i,{R:()=>t,x:()=>o});var s=e(6540);const r={},l=s.createContext(r);function t(n){const i=s.useContext(l);return s.useMemo(function(){return"function"==typeof n?n(i):{...i,...n}},[i,n])}function o(n){let i;return i=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:t(n.components),s.createElement(l.Provider,{value:i},n.children)}}}]);